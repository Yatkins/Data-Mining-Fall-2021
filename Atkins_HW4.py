# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hVdw78dxFoSYYUcGlAmIgQg4Z5N_ChNP
"""

!pip install pyspark
!wget http://snap.stanford.edu/class/cs246-data/browsing.txt

import pyspark
sc = pyspark.SparkContext()

lines = sc.textFile('browsing.txt')
baskets = lines.map(lambda l: sorted(l.split()))
N = baskets.count()
print("N:", N)

baskets.take(5)

def singles_helper(basket):
    ret = []
    for item in basket:
        ret.append((item, 1))
    return ret

singles_support = baskets.flatMap(singles_helper)
singles_support.take(5)

singles_support = singles_support.reduceByKey(lambda x, y: x + y)
singles_support.take(5)

print(singles_support.count())
singles_support = singles_support.filter(lambda x: x[1] >= 100)
print(singles_support.count())

singles = dict(singles_support.collect())

def doubles_helper(basket):
    ret = []
    for i in range(len(basket)):
        if basket[i] in singles:
            for j in range(i):
                if basket[j] in singles:
                    ret.append(((basket[j], basket[i]), 1)) # basket is sorted
    return ret

doubles_support = baskets.flatMap(doubles_helper)
doubles_support.take(5)
doubles_support.count()
      
doubles_support = doubles_support.reduceByKey(lambda x, y: x + y)
doubles_support.take(5)

print(doubles_support.count())
doubles_support = doubles_support.filter(lambda x: x[1] >= 100)
print(doubles_support.count())

doubles = dict(doubles_support.collect())

def confidence_doubles_helper(double_support):
    double, support = double_support
    support = float(support)
    u, v = double
    uv_conf = support / singles[u]
    vu_conf = support / singles[v]
    return (('%s -> %s' % (u, v), uv_conf),
            ('%s -> %s' % (v, u), vu_conf))

doubles_conf = doubles_support.flatMap(confidence_doubles_helper)
doubles_conf.take(3)
   
doubles_conf = doubles_conf.sortBy(lambda x: (-x[1], x[0]))
doubles_conf.take(5)

"""Create a list of candidate 3-item sets by merging two frequent item pairs. Two item pairs can generate a 3-item set if they have one element in common.
Read the data again so that the frequency of those candidate sets can be counted. This step should be done using the MapReduce model.
Remove those candidates that do not reach the support threshold  𝑠=100 .
Compute the confidence value for the remaining sets, and output the top 5 itemsets.
"""
#find two common pairs, if they have an item in common, add the pairs union to the triples
def triples_helper(basket):
    ret = []
    for i in range(len(basket)):
      for j in range(i+1, len(basket)):
        if ((str(basket[i],), str(basket[j]))) in doubles:
          for a in range(i):
            for b in range(j):
              if ((str(basket[a],), str(basket[b]))) in doubles:
                if basket[i] in ((str(basket[a],), str(basket[b]))) or basket[j] in ((str(basket[a],), str(basket[b]))): 
                  ret.append(((tuple(list(set((str(basket[i],), str(basket[j])) + (str(basket[a],), str(basket[b])))))), 1))
    return ret

#Map: find triples from each basket
triples_support = baskets.flatMap(triples_helper)
triples_support.take(5)
triples_support.count()
      
#Reduce: count frequnecy of 3-itemsets
triples_support = triples_support.reduceByKey(lambda x, y: x + y)
triples_support.take(5)

#filter 3-itemsets to only those with frequency of at least 100
print(triples_support.count())
triples_support = triples_support.filter(lambda x: x[1] >= 100)
print(triples_support.count())

#calculate the confidance of the pairs
def confidence_triples_helper(triple_support):
    triple, support = triple_support
    support = float(support)
    u, v, w = triple
    if (u,v) in doubles:
      uvw_conf = support / float(doubles[u,v])
    else:
      uvw_conf = support / float(doubles[v,u])
    if (w,v) in doubles:
      wvu_conf = support / float(doubles[w,v])
    else:
      wvu_conf = support / float(doubles[v,w])
    if (w,u) in doubles:
      wuv_conf = support / float(doubles[w,u])
    else:
      wuv_conf = support / float(doubles[u,w])
    return (('%s & %s -> %s' % (u, v, w), uvw_conf),
            ('%s & %s -> %s' % (w, v, u), wvu_conf),
            ('%s & %s -> %s' % (w, u, v), wuv_conf))

#return 5 of the confidence scores  
triples_conf = triples_support.flatMap(confidence_triples_helper)
triples_conf.take(5)

#return top 5 confidence scores
triples_conf = triples_conf.sortBy(lambda x: (-x[1], x[0]))
triples_conf.take(5)